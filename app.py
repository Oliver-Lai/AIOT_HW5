"""
AI vs Human Text Detector

A Streamlit web application that detects whether text content was generated by AI
(specifically ChatGPT) or written by a human using a pre-trained Hugging Face model.

Author: Senior Python Developer
Date: December 10, 2025
"""

import streamlit as st
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from typing import Dict, Any
import os

# Configuration Constants
AI_THRESHOLD = 0.70        # 70% for "AI Generated"
HUMAN_THRESHOLD = 0.70     # 70% for "Human Written"
MAX_CHAR_LIMIT = 5000      # Maximum input length
MODEL_NAME = "Hello-SimpleAI/chatgpt-detector-roberta"
TASK = "text-classification"
DEVICE = -1  # CPU (0 for GPU if available)
MODEL_CACHE_DIR = "./model_cache"  # Local cache directory


@st.cache_resource
def load_model():
    """
    Load and cache the Hugging Face model pipeline for text classification.
    
    This function uses @st.cache_resource to ensure the model is loaded only once
    and cached for subsequent requests, which is critical for Streamlit Cloud
    memory management. Models are cached locally to avoid repeated downloads.
    
    Returns:
        pipeline: Hugging Face pipeline object for text classification
        
    Raises:
        Exception: If model loading fails due to network or compatibility issues
    """
    try:
        # Create cache directory if it doesn't exist
        os.makedirs(MODEL_CACHE_DIR, exist_ok=True)
        
        # Set the Hugging Face cache directory via environment variable
        os.environ['TRANSFORMERS_CACHE'] = MODEL_CACHE_DIR
        
        # Load model and tokenizer with local caching
        classifier = pipeline(
            task=TASK,
            model=MODEL_NAME,
            device=DEVICE
        )
        return classifier
    except Exception as e:
        st.error(f"Failed to load model: {str(e)}")
        st.info("Troubleshooting tips:\n"
                "- Check your internet connection\n"
                "- Verify the model name is correct\n"
                "- Ensure all dependencies are installed")
        raise


def analyze_text(text: str, classifier) -> Dict[str, Any]:
    """
    Process text through the model and return structured results.
    
    Args:
        text (str): The input text to analyze
        classifier: The Hugging Face pipeline object
        
    Returns:
        dict: A dictionary containing:
            - ai_probability (float): Probability of AI-generated (0-100)
            - human_probability (float): Probability of human-written (0-100)
            - classification (str): "AI Generated", "Human Written", or "Mixed/Uncertain"
            - confidence_level (str): "High", "Medium", or "Low"
            
    Raises:
        Exception: If inference fails or output format is unexpected
    """
    try:
        # Truncate text if it's too long for the model (max ~512 tokens ‚âà 2000 chars)
        # This prevents indexing errors with very long texts
        MAX_MODEL_CHARS = 2000
        if len(text) > MAX_MODEL_CHARS:
            text = text[:MAX_MODEL_CHARS]
            
        # Run inference - returns list like [{'label': 'ChatGPT', 'score': 0.937}]
        # Using top_k=None to get all label scores
        results = classifier(text, top_k=None, truncation=True)
        
        # Extract probabilities
        ai_prob = 0.0
        human_prob = 0.0
        
        # results format: [[{'label': 'Human', 'score': 0.06}, {'label': 'ChatGPT', 'score': 0.94}]]
        if isinstance(results, list) and len(results) > 0:
            scores = results[0] if isinstance(results[0], list) else results
            
            for item in scores:
                if isinstance(item, dict):
                    label = item.get('label', '').strip()
                    score = item.get('score', 0.0)
                    
                    # ChatGPT label means AI-generated
                    if label == 'ChatGPT':
                        ai_prob = score * 100
                    # Human label means human-written
                    elif label == 'Human':
                        human_prob = score * 100
        
        # Ensure probabilities sum to 100%
        if ai_prob == 0.0 and human_prob > 0.0:
            ai_prob = 100 - human_prob
        elif human_prob == 0.0 and ai_prob > 0.0:
            human_prob = 100 - ai_prob
        
        # Determine classification
        if ai_prob > (AI_THRESHOLD * 100):
            classification = "AI Generated"
        elif human_prob > (HUMAN_THRESHOLD * 100):
            classification = "Human Written"
        else:
            classification = "Mixed/Uncertain"
        
        # Determine confidence level
        max_prob = max(ai_prob, human_prob)
        if max_prob > 85:
            confidence_level = "High"
        elif max_prob >= 70:
            confidence_level = "Medium"
        else:
            confidence_level = "Low"
        
        return {
            'ai_probability': ai_prob,
            'human_probability': human_prob,
            'classification': classification,
            'confidence_level': confidence_level
        }
        
    except Exception as e:
        st.error(f"Error during text analysis: {str(e)}")
        raise


def main():
    """
    Main application function that sets up the Streamlit UI and handles user interactions.
    """
    # Page configuration
    st.set_page_config(
        page_title="AI Content Detector",
        page_icon="üîç",
        layout="centered"
    )
    
    # Header Section
    st.title("üîç AI Content Detector")
    st.markdown("""
    This tool helps you detect whether text was generated by AI (ChatGPT) or written by a human.
    Simply paste your text below and click **Analyze Text** to see the results.
    """)
    
    st.info(f"**Model**: {MODEL_NAME} (trained to detect ChatGPT-generated text)")
    
    # Load model
    try:
        with st.spinner("Loading AI detection model..."):
            classifier = load_model()
    except Exception:
        st.stop()
    
    # Input Section
    st.markdown("---")
    st.subheader("üìù Enter Text to Analyze")
    
    text_input = st.text_area(
        label="Paste your text here:",
        height=200,
        max_chars=MAX_CHAR_LIMIT,
        placeholder="Paste the text you want to analyze here. The detector works best with at least a few sentences.",
        help=f"Maximum {MAX_CHAR_LIMIT} characters. Best results with 50+ words."
    )
    
    # Character count
    char_count = len(text_input)
    st.caption(f"Characters: {char_count}/{MAX_CHAR_LIMIT}")
    
    # Analyze button
    analyze_button = st.button("üîç Analyze Text", type="primary", use_container_width=True)
    
    # Analysis and Results
    if analyze_button:
        # Validation
        if not text_input or text_input.strip() == "":
            st.error("‚ö†Ô∏è Please enter some text to analyze.")
        else:
            # Warning for very long text
            if char_count > MAX_CHAR_LIMIT:
                st.warning(f"‚ö†Ô∏è Text exceeds {MAX_CHAR_LIMIT} characters. Results may take longer.")
            
            # Warning for very short text
            word_count = len(text_input.split())
            if word_count < 10:
                st.warning("‚ö†Ô∏è Text is very short. Results may have limited confidence.")
            
            # Perform analysis
            with st.spinner("üîÑ Analyzing text..."):
                try:
                    results = analyze_text(text_input, classifier)
                    
                    # Results Section
                    st.markdown("---")
                    st.subheader("üìä Analysis Results")
                    
                    # Progress bar for AI probability
                    st.markdown("**AI Detection Level:**")
                    st.progress(results['ai_probability'] / 100)
                    
                    # Main result display
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric(
                            label="AI Probability",
                            value=f"{results['ai_probability']:.1f}%"
                        )
                    with col2:
                        st.metric(
                            label="Human Probability",
                            value=f"{results['human_probability']:.1f}%"
                        )
                    
                    # Classification result with color coding
                    st.markdown("**Classification:**")
                    classification = results['classification']
                    
                    if classification == "Human Written":
                        st.success(f"‚úÖ This text appears to be **{classification}**")
                    elif classification == "AI Generated":
                        st.error(f"ü§ñ This text appears to be **{classification}**")
                    else:
                        st.warning(f"‚ùì This text shows **{classification}** signals")
                    
                    # Confidence level
                    confidence = results['confidence_level']
                    st.markdown(f"**Confidence Level:** {confidence}")
                    
                    if confidence == "Low":
                        st.warning("‚ö†Ô∏è Low confidence result. The text may be ambiguous or the model is uncertain. "
                                 "Try with longer or more distinctive text for better results.")
                    
                    # Interpretation guidance
                    with st.expander("‚ÑπÔ∏è How to interpret these results"):
                        st.markdown("""
                        **Understanding the Results:**
                        - **AI Generated (>70% AI)**: The text likely written by ChatGPT or similar AI
                        - **Human Written (>70% Human)**: The text likely written by a human
                        - **Mixed/Uncertain**: The model cannot definitively classify the text
                        
                        **Confidence Levels:**
                        - **High (>85%)**: Very confident in the classification
                        - **Medium (70-85%)**: Reasonably confident, but some uncertainty
                        - **Low (<70%)**: Uncertain classification, interpret with caution
                        
                        **Limitations:**
                        - Best performance with English text
                        - Trained specifically on ChatGPT-generated content
                        - May not detect other AI models accurately
                        - Very short texts may yield unreliable results
                        """)
                
                except Exception as e:
                    st.error(f"‚ùå An error occurred during analysis. Please try again.")
                    st.exception(e)
    
    # Footer
    st.markdown("---")
    st.caption("üí° This tool uses machine learning and may not be 100% accurate. "
               "Use results as guidance, not definitive proof.")


if __name__ == "__main__":
    main()

# Project Context

## Purpose
AIOT_HW5 is an AI vs Human Text Detector web application that helps users identify whether text content was generated by AI (specifically ChatGPT) or written by a human. The application provides an accessible, user-friendly interface for text authenticity verification.

## Tech Stack
- Python 3.8+
- Streamlit (web application framework)
- Hugging Face Transformers (ML model integration)
- PyTorch (ML backend)
- Hello-SimpleAI/chatgpt-detector-roberta (pre-trained detection model)

## Project Conventions

### Code Style
- Follow PEP 8 Python style guidelines
- Use clear, descriptive variable and function names
- Add docstrings to all functions using Google-style format
- Include type hints where appropriate
- Keep functions focused and single-purpose
- Use constants for configuration values (uppercase naming)

### Architecture Patterns
- Single-page Streamlit application design
- Functional programming approach for core logic
- Resource caching using `@st.cache_resource` for model loading
- Separation of concerns: UI layer, logic layer, model layer
- Stateless analysis (no persistent data storage)

### Testing Strategy
- Manual testing for UI components and user flows
- Functional testing with known AI and human text samples
- Edge case testing (empty input, very long text, special characters)
- Deployment testing on Streamlit Cloud environment
- Performance testing for inference time and memory usage

### Git Workflow
- Main branch for stable, deployable code
- Feature branches for development work
- Clear, descriptive commit messages
- Changes follow OpenSpec proposal → implementation → archive workflow

## Domain Context
- **AI Detection**: The model specifically detects ChatGPT-generated content
- **Classification Thresholds**: 70% probability used as threshold for definitive classification
- **Confidence Levels**: Based on probability spreads (High: >85%, Medium: 70-85%, Low: <70%)
- **Use Cases**: Education, content moderation, writing verification, research

## Important Constraints
- Must operate within Streamlit Cloud free tier limits (~1GB memory)
- Model must be cached to prevent re-initialization (critical for performance)
- CPU-only deployment (no GPU available on Streamlit Cloud)
- No user authentication or data persistence required
- Single-language support (English) in initial version
- Inference time must be under 10 seconds for typical inputs

## External Dependencies
- Hugging Face Model Hub: Source for pre-trained model
- Streamlit Cloud: Deployment platform
- Python Package Index (PyPI): Dependency source
- No external APIs requiring authentication

# AI Content Detector ğŸ”

A Streamlit web application that detects whether text content was generated by AI (specifically ChatGPT) or written by a human using a pre-trained Hugging Face transformer model.

## Features

- ğŸ¤– **AI Detection**: Uses the "Hello-SimpleAI/chatgpt-detector-roberta" model for accurate detection
- ğŸ“Š **Visual Results**: Clear progress bars and color-coded status messages
- ğŸ’¯ **Probability Metrics**: Shows exact percentages for AI vs Human probability
- âš¡ **Fast & Efficient**: Optimized with model caching for quick responses
- ğŸ¯ **Confidence Levels**: Displays High/Medium/Low confidence indicators
- ğŸŒ **Easy to Use**: Simple web interface, no technical knowledge required

## Installation

### Prerequisites

- Python 3.8 or higher
- pip (Python package manager)

### Setup Instructions

1. **Clone the repository**
   ```bash
   git clone https://github.com/Oliver-Lai/AIOT_HW5.git
   cd AIOT_HW5
   ```

2. **Create a virtual environment (recommended)**
   ```bash
   python -m venv venv
   
   # On Windows
   venv\Scripts\activate
   
   # On macOS/Linux
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Pre-download the model (recommended)**
   ```bash
   python download_model.py
   ```
   This will download the AI detection model (~1.5GB) to a local cache directory.
   Users won't need to download it again when opening the app.

## Usage

### Running Locally

1. **Pre-download the model (first time only)**
   ```bash
   python download_model.py
   ```
   This step is optional but highly recommended. It downloads the model once,
   so the app starts faster and works offline after initial download.

2. **Start the application**
   ```bash
   streamlit run app.py
   ```

3. **Open your browser**
   - The application will automatically open at `http://localhost:8501`
   - If it doesn't open automatically, navigate to the URL shown in the terminal

3. **Analyze text**
   - Paste your text into the text area
   - Click "Analyze Text"
   - View the results with AI/Human probabilities

### Example Workflow

1. Copy text you want to analyze
2. Paste it into the text area (works best with 50+ words)
3. Click the "Analyze Text" button
4. Review the results:
   - **Green**: Human written (>70% confidence)
   - **Red**: AI generated (>70% confidence)
   - **Yellow**: Mixed/Uncertain

## Deployment to Streamlit Cloud

### æ–¹æ³•ä¸€ï¼šè‡ªå‹•éƒ¨ç½²ï¼ˆæ¨è–¦ï¼‰

Streamlit Cloud æœƒåœ¨é¦–æ¬¡éƒ¨ç½²æ™‚è‡ªå‹•ä¸‹è¼‰ä¸¦ç·©å­˜æ¨¡å‹ã€‚

1. **Push to GitHub**
   ```bash
   git add .
   git commit -m "Add AI content detector"
   git push origin main
   ```

2. **Deploy on Streamlit Cloud**
   - Go to [share.streamlit.io](https://share.streamlit.io)
   - Sign in with GitHub
   - Click "New app"
   - Select your repository: `Oliver-Lai/AIOT_HW5`
   - Set main file path: `app.py`
   - Click "Deploy"

3. **é¦–æ¬¡éƒ¨ç½²**
   - é¦–æ¬¡éƒ¨ç½²éœ€è¦ 5-10 åˆ†é˜ï¼ˆä¸‹è¼‰æ¨¡å‹ï¼‰
   - Streamlit Cloud æœƒè‡ªå‹•ç·©å­˜æ¨¡å‹
   - å¾ŒçºŒé‡å•Ÿæˆ–æ›´æ–°æœƒä½¿ç”¨ç·©å­˜ï¼ˆ<1 åˆ†é˜ï¼‰

4. **é‡è¦èªªæ˜**
   - âœ… æ¨¡å‹æœƒè¢« Streamlit Cloud è‡ªå‹•ç·©å­˜
   - âœ… ä¸éœ€è¦å°‡æ¨¡å‹æ–‡ä»¶æäº¤åˆ° Git
   - âœ… æ›´æ–°ä»£ç¢¼ä¸æœƒé‡æ–°ä¸‹è¼‰æ¨¡å‹
   - âœ… åªæœ‰åˆªé™¤æ‡‰ç”¨é‡æ–°éƒ¨ç½²æ‰éœ€è¦é‡æ–°ä¸‹è¼‰

### æ–¹æ³•äºŒï¼šé å…ˆä¸‹è¼‰æ¨¡å‹å¾Œéƒ¨ç½²

å¦‚æœä½ æƒ³ç¢ºä¿æ¨¡å‹å·²æº–å‚™å¥½ï¼š

1. **æœ¬åœ°é ä¸‹è¼‰æ¨¡å‹**
   ```bash
   python download_model.py
   ```

2. **å°‡ model_cache æ–‡ä»¶å¤¾å£“ç¸®ï¼ˆå¯é¸ï¼‰**
   ```bash
   # æ³¨æ„ï¼šé€™æœƒå‰µå»ºä¸€å€‹ ~500MB çš„å£“ç¸®æ–‡ä»¶
   tar -czf model_cache.tar.gz model_cache/
   ```

3. **ä½¿ç”¨ Git LFSï¼ˆLarge File Storageï¼‰**
   ```bash
   # å®‰è£ Git LFS
   git lfs install
   
   # è¿½è¹¤å¤§å‹æ–‡ä»¶
   git lfs track "model_cache.tar.gz"
   git add .gitattributes
   git add model_cache.tar.gz
   git commit -m "Add cached model"
   git push origin main
   ```

âš ï¸ **ä¸æ¨è–¦æ–¹æ³•äºŒçš„åŸå› **ï¼š
- Git å€‰åº«æœƒè®Šå¾—å¾ˆå¤§ï¼ˆ~500MB+ï¼‰
- Clone å’Œ Pull æœƒå¾ˆæ…¢
- Streamlit Cloud æœƒè‡ªå‹•è™•ç†æ¨¡å‹ç·©å­˜
- å…è²»çš„ Git LFS é…é¡æœ‰é™

### æ¨è–¦åšæ³•

**âœ… æœ€ä½³å¯¦è¸**ï¼šè®“ Streamlit Cloud è‡ªå‹•è™•ç†
- ç¬¬ä¸€æ¬¡éƒ¨ç½²ç­‰å¾… 5-10 åˆ†é˜
- æ¨¡å‹æœƒè¢« Streamlit Cloud æ°¸ä¹…ç·©å­˜
- ä»£ç¢¼æ›´æ–°ä¸æœƒå½±éŸ¿æ¨¡å‹ç·©å­˜
- å®Œå…¨è‡ªå‹•åŒ–ï¼Œç„¡éœ€æ‰‹å‹•ç®¡ç†

## How It Works

### Model Information

- **Model**: [Hello-SimpleAI/chatgpt-detector-roberta](https://huggingface.co/Hello-SimpleAI/chatgpt-detector-roberta)
- **Type**: RoBERTa-based text classification
- **Training**: Specifically trained to detect ChatGPT-generated text
- **Backend**: PyTorch (CPU-optimized)

### Classification Logic

- **AI Generated**: AI probability > 70%
- **Human Written**: Human probability > 70%
- **Mixed/Uncertain**: Neither exceeds 70%

### Confidence Levels

- **High**: Maximum probability > 85%
- **Medium**: Maximum probability 70-85%
- **Low**: Maximum probability < 70%

## Technical Details

### Architecture

- **Frontend**: Streamlit (Python-based web framework)
- **ML Framework**: Hugging Face Transformers
- **Model Caching**: `@st.cache_resource` for memory optimization
- **Device**: CPU-only (compatible with Streamlit Cloud)

### Performance

- **Model Size**: ~500MB
- **Memory Usage**: <1GB total
- **Inference Time**: 1-5 seconds per analysis
- **First Run**: May take longer due to model download

### Input Constraints

- **Maximum Length**: 5,000 characters
- **Recommended Length**: 50+ words for best results
- **Language**: Optimized for English text

## Limitations

âš ï¸ **Important Notes:**

1. **Model Specificity**: Trained specifically for ChatGPT detection; may not accurately detect other AI models
2. **Language Support**: Best performance with English text
3. **Short Texts**: Very short texts (<10 words) may yield unreliable results
4. **Not Definitive**: Use results as guidance, not absolute proof
5. **Evolving AI**: As AI models evolve, detection accuracy may vary

## Troubleshooting

### Model Loading Issues

**Problem**: "Failed to load model" error

**Solutions**:
- Check your internet connection
- Verify you have enough disk space (~2GB for model cache)
- Ensure all dependencies are installed correctly
- Try running `pip install -r requirements.txt --upgrade`

### Memory Issues

**Problem**: Application crashes or runs out of memory

**Solutions**:
- Close other applications to free up RAM
- The model requires ~1GB of available memory
- On Streamlit Cloud, this should be handled automatically

### Slow Performance

**Problem**: Analysis takes too long

**Solutions**:
- First analysis may be slower due to model initialization
- Subsequent analyses should be faster (1-5 seconds)
- Very long texts (>1000 words) may take longer to process

## Dependencies

- `streamlit>=1.28.0,<2.0.0` - Web application framework
- `transformers>=4.30.0,<5.0.0` - Hugging Face model integration
- `torch>=2.0.0,<3.0.0` - PyTorch ML backend

See `requirements.txt` for complete dependency list.

## Project Structure

```
AIOT_HW5/
â”œâ”€â”€ app.py                  # Main Streamlit application
â”œâ”€â”€ download_model.py       # Script to pre-download model
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ AGENTS.md              # OpenSpec instructions
â”œâ”€â”€ model_cache/           # Cached model files (auto-generated)
â””â”€â”€ openspec/              # OpenSpec proposal and specs
    â”œâ”€â”€ project.md         # Project context
    â”œâ”€â”€ changes/           # Change proposals
    â””â”€â”€ specs/            # Capability specifications
```

## Contributing

This project follows the OpenSpec workflow for changes:

1. Review `openspec/AGENTS.md` for guidelines
2. Create proposals in `openspec/changes/`
3. Implement according to `tasks.md`
4. Archive completed changes

## License

This project is available for educational and research purposes.

## Acknowledgments

- **Model**: [Hello-SimpleAI/chatgpt-detector-roberta](https://huggingface.co/Hello-SimpleAI/chatgpt-detector-roberta)
- **Framework**: [Streamlit](https://streamlit.io)
- **ML Library**: [Hugging Face Transformers](https://huggingface.co/transformers)

## Contact

For issues, questions, or suggestions, please open an issue on GitHub.

---

**Made with â¤ï¸ using Streamlit and Hugging Face**